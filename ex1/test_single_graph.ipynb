{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from loguru import logger\n",
    "# import wandb\n",
    "import json\n",
    "\n",
    "import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import train\n",
    "import test\n",
    "import utils\n",
    "\n",
    "# from model.bipn import BIPN\n",
    "# from model.mbcgcn import MBCGCN\n",
    "from model.lightGCN import LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# hyper parameter setting\n",
    "parser.add_argument('--embedding_size', type=int, default=64, help='Choose Embedding size')\n",
    "parser.add_argument('--reg_weight', type=float, default=1e-3, help='')\n",
    "parser.add_argument('--log_reg', type=float, default=0.5, help='')\n",
    "parser.add_argument('--layers', type=int, default=2)\n",
    "parser.add_argument('--node_dropout', type=float, default=0.75)\n",
    "parser.add_argument('--message_dropout', type=float, default=0.25)\n",
    "parser.add_argument('--omega', type=float, default=1)\n",
    "parser.add_argument('--gamma', type=float, default=1e-10)\n",
    "\n",
    "# data setting\n",
    "parser.add_argument('--data_name', type=str, default='beibei', help='choose data name')\n",
    "parser.add_argument('--loss', type=str, default='bpr', help='')\n",
    "parser.add_argument('--negative_cnt', type=int, default=4, help='Number of negative sample')\n",
    "parser.add_argument('--num_workers', default=4, type=int, help='workers of dataloader')\n",
    "\n",
    "parser.add_argument('--if_load_model', type=bool, default=False, help='')\n",
    "parser.add_argument('--topk', type=list, default=[10, 20, 50, 80], help='')\n",
    "parser.add_argument('--metrics', type=list, default=['hit', 'ndcg'], help='')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='')\n",
    "parser.add_argument('--decay', type=float, default=0.001, help='')\n",
    "parser.add_argument('--batch_size', type=int, default=1024, help='set batch size')\n",
    "parser.add_argument('--min_epoch', type=str, default=5, help='')\n",
    "parser.add_argument('--epochs', type=str, default=200, help='')\n",
    "parser.add_argument('--model_path', type=str, default='./check_point', help='')\n",
    "parser.add_argument('--check_point', type=str, default='', help='')\n",
    "parser.add_argument('--model_name', type=str, default='BIPN', help='')\n",
    "\n",
    "parser.add_argument('--gpu_id', default=3, type=int, help='gpu_number')\n",
    "parser.add_argument('--train', default=True, type=eval, help='choose train or test')\n",
    "parser.add_argument('--model', default='ligthGCN', type=str, help='model name')\n",
    "parser.add_argument('--behv', default='buy', type=str, help='behavior name')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f'cuda:{0}')\n",
    "\n",
    "if args.data_name == 'tmall':\n",
    "    args.data_pth = '/disks/ssd1/jahyeok/MBR_data/Tmall'\n",
    "    args.behaviors = ['buy', 'click', 'collect', 'cart']\n",
    "elif args.data_name == 'taobao':\n",
    "    args.data_pth = '/disks/ssd1/jahyeok/MBR_data/taobao'\n",
    "    args.behaviors = ['buy', 'view', 'cart']\n",
    "elif args.data_name == 'beibei':\n",
    "    args.data_pth = '/disks/ssd1/jahyeok/MBR_data/beibei'\n",
    "    args.behaviors = ['buy', 'view', 'cart']\n",
    "else:\n",
    "    raise Exception('data_name cannot be None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beibei'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_file_pth = os.path.join(args.data_pth, 'count.txt')\n",
    "with open(os.path.join(cnt_file_pth), encoding='utf-8') as r:\n",
    "    cnt_data = json.load(r)\n",
    "    N_user = cnt_data['user']\n",
    "    N_item = cnt_data['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = dataset.TestDataset(os.path.join(args.data_pth, 'test.txt'))\n",
    "test_dl = DataLoader(dataset=test_data,\n",
    "                        num_workers=args.num_workers,\n",
    "                        batch_size=args.batch_size)\n",
    "\n",
    "# make matrices which we need\n",
    "inter_matrix, user_item_inter_set, all_inter_matrix, dicts = utils.make_inter_matrix(args.data_pth, args.behaviors, N_user, N_item)\n",
    "matrix_list = []\n",
    "matrix_list.append(inter_matrix)\n",
    "matrix_list.append(user_item_inter_set)\n",
    "matrix_list.append(all_inter_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_pth = '/home/jahyeok/Desktop/hdd2_sl/jahyeok/urop/ex1_checkpoint/check_point/beibei/buy/0.001/2/model.pth'\n",
    "cart_pth = '/home/jahyeok/Desktop/hdd2_sl/jahyeok/urop/ex1_checkpoint/check_point/beibei/cart/0.001/2/model.pth'\n",
    "view_pth = '/home/jahyeok/Desktop/hdd2_sl/jahyeok/urop/ex1_checkpoint/check_point/beibei/view/0.001/2/model.pth'\n",
    "\n",
    "buy_dict = torch.load(buy_pth, map_location=device, weights_only=True)\n",
    "cart_dict = torch.load(cart_pth, map_location=device, weights_only=True)\n",
    "view_dict = torch.load(view_pth, map_location=device, weights_only=True)\n",
    "\n",
    "model_buy = LightGCN(args, device, args.layers, N_user+1, N_item+1, matrix_list[0][0]).to(device)\n",
    "model_cart = LightGCN(args, device, args.layers, N_user+1, N_item+1, matrix_list[0][2]).to(device)\n",
    "model_view = LightGCN(args, device, args.layers, N_user+1, N_item+1, matrix_list[0][1]).to(device)\n",
    "\n",
    "model_buy.load_state_dict(buy_dict)\n",
    "model_cart.load_state_dict(cart_dict)\n",
    "model_view.load_state_dict(view_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_pth = '/home/jahyeok/Desktop/hdd2_sl/jahyeok/urop/ex1_checkpoint/check_point/tmall/buy/0.001/2/model.pth'\n",
    "cart_pth = '/home/jahyeok/Desktop/hdd2_sl/jahyeok/urop/ex1_checkpoint/check_point/tmall/cart/0.001/2/model.pth'\n",
    "click_pth = '/home/jahyeok/Desktop/hdd2_sl/jahyeok/urop/ex1_checkpoint/check_point/tmall/click/0.001/2/model.pth'\n",
    "collect_pth = '/home/jahyeok/Desktop/hdd2_sl/jahyeok/urop/ex1_checkpoint/check_point/tmall/collect/0.001/2/model.pth'\n",
    "\n",
    "buy_dict = torch.load(buy_pth, map_location=device, weights_only=True)\n",
    "cart_dict = torch.load(cart_pth, map_location=device, weights_only=True)\n",
    "click_dict = torch.load(click_pth, map_location=device, weights_only=True)\n",
    "collect_dict = torch.load(collect_pth, map_location=device, weights_only=True)\n",
    "\n",
    "model_buy = LightGCN(args, device, args.layers, N_user+1, N_item+1, matrix_list[0][0]).to(device)\n",
    "model_cart = LightGCN(args, device, args.layers, N_user+1, N_item+1, matrix_list[0][3]).to(device)\n",
    "model_click = LightGCN(args, device, args.layers, N_user+1, N_item+1, matrix_list[0][1]).to(device)\n",
    "model_collect = LightGCN(args, device, args.layers, N_user+1, N_item+1, matrix_list[0][2]).to(device)\n",
    "\n",
    "model_buy.load_state_dict(buy_dict)\n",
    "model_cart.load_state_dict(cart_dict)\n",
    "model_click.load_state_dict(click_dict)\n",
    "model_collect.load_state_dict(collect_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "weight_range = np.arange(0, 1.1, 0.1)\n",
    "combinations = [(a, b, 1 - a - b) for a, b in product(weight_range, repeat=2) if 0 <= 1 - a - b <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_result(args, topk_list, gt_len):\n",
    "    result_list = []\n",
    "    for metric in args.metrics:\n",
    "        metric_fuc = metrics_dict[metric.lower()]\n",
    "        result = metric_fuc(topk_list, gt_len)\n",
    "        result_list.append(result)\n",
    "    result_list = np.stack(result_list, axis=0).mean(axis=1)\n",
    "    metric_dict = {}\n",
    "    for topk in args.topk:\n",
    "        for metric, value in zip(args.metrics, result_list):\n",
    "            key = '{}@{}'.format(metric, topk)\n",
    "            metric_dict[key] = np.round(value[topk - 1], 4)\n",
    "\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_length = utils.make_gt_length(args.data_pth, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " recording optimal weights: (0.0, 0.0, 1.0) with score: 0.0423\n",
      " recording optimal weights: (0.0, 0.1, 0.9) with score: 0.0534\n",
      " recording optimal weights: (0.0, 0.2, 0.8) with score: 0.062\n",
      " recording optimal weights: (0.0, 0.30000000000000004, 0.7) with score: 0.0678\n",
      " recording optimal weights: (0.0, 0.4, 0.6) with score: 0.0722\n",
      " recording optimal weights: (0.0, 0.5, 0.5) with score: 0.0732\n",
      " recording optimal weights: (0.1, 0.1, 0.8) with score: 0.076\n",
      " recording optimal weights: (0.1, 0.2, 0.7) with score: 0.0848\n",
      " recording optimal weights: (0.1, 0.30000000000000004, 0.6) with score: 0.0898\n",
      " recording optimal weights: (0.1, 0.4, 0.5) with score: 0.0922\n",
      " recording optimal weights: (0.2, 0.2, 0.6000000000000001) with score: 0.097\n",
      " recording optimal weights: (0.2, 0.30000000000000004, 0.5) with score: 0.1007\n",
      " recording optimal weights: (0.2, 0.4, 0.4) with score: 0.1008\n",
      " recording optimal weights: (0.30000000000000004, 0.2, 0.49999999999999994) with score: 0.1037\n",
      " recording optimal weights: (0.30000000000000004, 0.30000000000000004, 0.3999999999999999) with score: 0.1063\n",
      " recording optimal weights: (0.4, 0.30000000000000004, 0.29999999999999993) with score: 0.1067\n",
      "(0.4, 0.30000000000000004, 0.29999999999999993)\n",
      "{'hit@10': 0.1067, 'ndcg@10': 0.0388, 'hit@20': 0.1651, 'ndcg@20': 0.0484, 'hit@50': 0.2695, 'ndcg@50': 0.0616, 'hit@80': 0.3313, 'ndcg@80': 0.068}\n"
     ]
    }
   ],
   "source": [
    "from metrics import metrics_dict\n",
    "\n",
    "max_score = float('-inf')\n",
    "optimal_weights = (0, 0 , 0)\n",
    "\n",
    "model_buy.eval()\n",
    "model_cart.eval()\n",
    "model_view.eval()\n",
    "\n",
    "final_metric = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (a, b, c) in combinations:\n",
    "\n",
    "        topk_list = []\n",
    "\n",
    "        for idx, data in enumerate(test_dl):\n",
    "            data = data.to(device)\n",
    "            start = time.time()\n",
    "            \n",
    "            users = data[:, 0]\n",
    "\n",
    "            scores_buy = model_buy.full_predict(users)\n",
    "            scores_cart = model_cart.full_predict(users)\n",
    "            scores_view = model_view.full_predict(users)\n",
    "\n",
    "            scores = a * scores_buy + b * scores_cart + c * scores_view\n",
    "\n",
    "            for index, user in enumerate(users):\n",
    "                user_score = scores[index]\n",
    "                items = [int(item) for item in dicts['buy'].get(str(user.item()))]\n",
    "                if items is not None:\n",
    "                    user_score[items] = -np.inf\n",
    "                _, topk_idx = torch.topk(user_score, max(args.topk), dim=-1)\n",
    "                gt_items = data[index, 1]\n",
    "                mask = np.isin(topk_idx.cpu().numpy(), gt_items.cpu().numpy())\n",
    "                topk_list.append(mask)\n",
    "\n",
    "        topk_list = np.array(topk_list)\n",
    "        metric_dict = calculate_result(args, topk_list, gt_length)\n",
    "\n",
    "        final_score = metric_dict['hit@10']\n",
    "        if final_score > max_score:\n",
    "            final_metric = metric_dict\n",
    "            max_score = final_score\n",
    "            optimal_weights = (a, b, c)\n",
    "            print(f' recording optimal weights: {optimal_weights} with score: {max_score}')\n",
    "\n",
    "print(optimal_weights)\n",
    "print(final_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " recording optimal weights: (0.0, 0.0, 0.0) with score: 0.0406\n",
      " recording optimal weights: (0.0, 0.0, 0.1) with score: 0.0948\n",
      " recording optimal weights: (0.0, 0.0, 0.2) with score: 0.1002\n",
      " recording optimal weights: (0.0, 0.0, 0.30000000000000004) with score: 0.1066\n",
      " recording optimal weights: (0.0, 0.0, 0.4) with score: 0.1148\n",
      " recording optimal weights: (0.0, 0.0, 0.5) with score: 0.1225\n",
      " recording optimal weights: (0.0, 0.0, 0.6000000000000001) with score: 0.1286\n",
      " recording optimal weights: (0.0, 0.0, 0.7000000000000001) with score: 0.1314\n",
      " recording optimal weights: (0.1, 0.0, 0.6000000000000001) with score: 0.1334\n",
      " recording optimal weights: (0.1, 0.0, 0.7000000000000001) with score: 0.1348\n",
      "(0.1, 0.0, 0.7000000000000001)\n",
      "{'hit@10': 0.1348, 'ndcg@10': 0.0711, 'hit@20': 0.1784, 'ndcg@20': 0.0807, 'hit@50': 0.2511, 'ndcg@50': 0.0935, 'hit@80': 0.2947, 'ndcg@80': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from metrics import metrics_dict\n",
    "\n",
    "max_score = float('-inf')\n",
    "optimal_weights = (0, 0 , 0)\n",
    "\n",
    "model_buy.eval()\n",
    "model_cart.eval()\n",
    "model_click.eval()\n",
    "model_collect.eval()\n",
    "\n",
    "final_metric = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (a, b, c, d) in combinations:\n",
    "\n",
    "        topk_list = []\n",
    "\n",
    "        for idx, data in enumerate(test_dl):\n",
    "            data = data.to(device)\n",
    "            start = time.time()\n",
    "            \n",
    "            users = data[:, 0]\n",
    "\n",
    "            scores_buy = model_buy.full_predict(users)\n",
    "            scores_cart = model_cart.full_predict(users)\n",
    "            scores_click = model_click.full_predict(users)\n",
    "            scores_collect = model_collect.full_predict(users)\n",
    "\n",
    "            scores = a * scores_buy + b * scores_cart + c * scores_click + d * scores_collect\n",
    "\n",
    "            for index, user in enumerate(users):\n",
    "                user_score = scores[index]\n",
    "                items = [int(item) for item in dicts['buy'].get(str(user.item()))]\n",
    "                if items is not None:\n",
    "                    user_score[items] = -np.inf\n",
    "                _, topk_idx = torch.topk(user_score, max(args.topk), dim=-1)\n",
    "                gt_items = data[index, 1]\n",
    "                mask = np.isin(topk_idx.cpu().numpy(), gt_items.cpu().numpy())\n",
    "                topk_list.append(mask)\n",
    "\n",
    "        topk_list = np.array(topk_list)\n",
    "        metric_dict = calculate_result(args, topk_list, gt_length)\n",
    "\n",
    "        final_score = metric_dict['hit@10']\n",
    "        if final_score > max_score:\n",
    "            final_metric = metric_dict\n",
    "            max_score = final_score\n",
    "            optimal_weights = (a, b, c)\n",
    "            print(f' recording optimal weights: {optimal_weights} with score: {max_score}')\n",
    "\n",
    "print(optimal_weights)\n",
    "print(final_metric)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jh1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
